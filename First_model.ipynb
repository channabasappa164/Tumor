{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMvLxkJBrBgMdfDuOrJ88Oh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# import os\n","# import matplotlib.pyplot as plt\n","# import matplotlib.image as mpimg\n","# import numpy as np\n","# import cv2\n","# from sklearn.model_selection import train_test_split\n","# from tensorflow.keras.models import Sequential\n","# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","# from tensorflow.keras.utils import to_categorical\n","# from google.colab import drive\n","\n","# # Mount Google Drive\n","# drive.mount('/content/gdrive')\n","\n","# # Function to print all images in a folder\n","# def print_images(folder):\n","#     for filename in os.listdir(folder):\n","#         if filename.endswith(('.jpg', '.jpeg', '.png')):  # Check if the file is an image\n","#             img_path = os.path.join(folder, filename)\n","#             img = mpimg.imread(img_path)\n","#             plt.imshow(img)\n","#             plt.title(filename)  # Use filename as the title\n","#             plt.axis('off')  # Turn off axis\n","#             plt.show()\n","\n","# # Specify the folder containing the images\n","# # folder_path = '/content/gdrive/MyDrive/yes'  # Replace with the path to your folder\n","\n","# # Print all images in the folder\n","# print_images(folder_path)\n","\n","# # Function to load and preprocess images from the directory\n","# def load_images_from_folder(folder):\n","#     images = []\n","#     for filename in os.listdir(folder):\n","#         img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_GRAYSCALE)\n","#         if img is not None:\n","#             img = cv2.resize(img, (150, 150))  # Resize image to ensure uniform dimensions\n","#             images.append(img)\n","#     return images\n","\n","# # Load images and labels\n","# yes_images = load_images_from_folder('/content/gdrive/MyDrive/yes')  # Folder containing images of people with brain tumor\n","# no_images = load_images_from_folder('/content/gdrive/MyDrive/no')    # Folder containing images of people without brain tumor\n","\n","# # Preprocess images and labels\n","# X_yes = np.array(yes_images)\n","# X_no = np.array(no_images)\n","# X = np.concatenate([X_yes, X_no]) / 255.0  # Normalize pixel values\n","# y = np.concatenate([np.ones(len(X_yes)), np.zeros(len(X_no))])  # Labels (1 for yes, 0 for no)\n","# y = to_categorical(y)  # Convert labels to one-hot encoding\n","\n","# # Split data into training and testing sets\n","# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# # Define the model\n","# model = Sequential()\n","# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)))  # Adjust input shape according to image dimensions\n","# model.add(MaxPooling2D((2, 2)))\n","# model.add(Conv2D(64, (3, 3), activation='relu'))\n","# model.add(MaxPooling2D((2, 2)))\n","# model.add(Flatten())\n","# model.add(Dense(64, activation='relu'))\n","# model.add(Dropout(0.5))\n","# model.add(Dense(2, activation='softmax'))  # Output layer with 2 units (yes or no)\n","\n","# # Compile the model\n","# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# # Train the model\n","# model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n","\n","# # Evaluate the model\n","# loss, accuracy = model.evaluate(X_test, y_test)\n","# print(\"Test Loss:\", loss)\n","# print(\"Test Accuracy:\", accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"17M9oRxit5ud3WWLp9x65Aocs3ZDkYpL7"},"id":"OUSEEyx-AswC","executionInfo":{"status":"ok","timestamp":1711200512351,"user_tz":-330,"elapsed":114549,"user":{"displayName":"Team RUNN!!","userId":"00800619849543446011"}},"outputId":"6c5e7e05-778d-4495-f7d7-309c7aadd5e0"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"JVkcM2ayZGk7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[".\n","import os\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import numpy as np\n","import cv2\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.utils import to_categorical\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/gdrive')\n","\n","# Function to print all images in a folder\n","def print_images(folder):\n","    for filename in os.listdir(folder):\n","        if filename.endswith(('.jpg', '.jpeg', '.png')):  # Check if the file is an image\n","            img_path = os.path.join(folder, filename)\n","            img = mpimg.imread(img_path)\n","            plt.imshow(img)\n","            plt.title(filename)  # Use filename as the title\n","            plt.axis('off')  # Turn off axis\n","            plt.show()\n","\n","# Function to load and preprocess images from the directory\n","def load_images_and_labels(folder_paths):\n","    images = []\n","    labels = []\n","    filenames = []\n","    for i, folder_path in enumerate(folder_paths):\n","        for filename in os.listdir(folder_path):\n","            img = cv2.imread(os.path.join(folder_path, filename), cv2.IMREAD_GRAYSCALE)\n","            if img is not None:\n","                img = cv2.resize(img, (150, 150))  # Resize image to ensure uniform dimensions\n","                images.append(img)\n","                labels.append(i)  # Assign label based on folder index (0 for no, 1 for yes)\n","                filenames.append(filename)  # Store filename\n","    return images, labels, filenames\n","\n","# Load images, labels, and filenames\n","yes_folder = '/content/gdrive/MyDrive/yes'  # Folder containing images of people with brain tumor\n","no_folder = '/content/gdrive/MyDrive/no'    # Folder containing images of people without brain tumor\n","images, labels, filenames = load_images_and_labels([no_folder, yes_folder])\n","\n","# Preprocess images and labels\n","X = np.array(images) / 255.0  # Normalize pixel values\n","y = to_categorical(labels)  # Convert labels to one-hot encoding\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test, filenames_train, filenames_test = train_test_split(X, y, filenames, test_size=0.2, random_state=42)\n","\n","# Define the model\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)))  # Adjust input shape according to image dimensions\n","model.add(MaxPooling2D((2, 2)))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2, 2)))\n","model.add(Flatten())\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(2, activation='softmax'))  # Output layer with 2 units (yes or no)\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n","\n","# Evaluate the model\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(\"Test Loss:\", loss)\n","print(\"Test Accuracy:\", accuracy)\n","\n","# Predict on all images\n","predictions = model.predict(X)\n","\n","# Classify images based on predictions\n","tumor_images = []\n","non_tumor_images = []\n","for i, pred in enumerate(predictions):\n","    if np.argmax(pred) == 1:\n","        tumor_images.append(filenames[i])\n","    else:\n","        non_tumor_images.append(filenames[i])\n","\n","print(\"Images with Tumor:\", tumor_images)\n","print(\"Images without Tumor:\", non_tumor_images)\n"],"metadata":{"id":"XNJ2VRiMZGgQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711215250309,"user_tz":-330,"elapsed":159547,"user":{"displayName":"Team RUNN!!","userId":"00800619849543446011"}},"outputId":"38400ebd-568c-449e-8271-f41602cf2fde"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","Epoch 1/10\n","7/7 [==============================] - 8s 875ms/step - loss: 0.9237 - accuracy: 0.5990 - val_loss: 0.5505 - val_accuracy: 0.7843\n","Epoch 2/10\n","7/7 [==============================] - 7s 964ms/step - loss: 0.5642 - accuracy: 0.7327 - val_loss: 0.5105 - val_accuracy: 0.8039\n","Epoch 3/10\n","7/7 [==============================] - 6s 791ms/step - loss: 0.5053 - accuracy: 0.7921 - val_loss: 0.4866 - val_accuracy: 0.8039\n","Epoch 4/10\n","7/7 [==============================] - 7s 1s/step - loss: 0.4667 - accuracy: 0.7871 - val_loss: 0.4785 - val_accuracy: 0.8235\n","Epoch 5/10\n","7/7 [==============================] - 6s 859ms/step - loss: 0.3994 - accuracy: 0.8218 - val_loss: 0.4868 - val_accuracy: 0.8431\n","Epoch 6/10\n","7/7 [==============================] - 6s 804ms/step - loss: 0.3234 - accuracy: 0.8564 - val_loss: 0.5233 - val_accuracy: 0.8431\n","Epoch 7/10\n","7/7 [==============================] - 7s 1s/step - loss: 0.2576 - accuracy: 0.8960 - val_loss: 0.5676 - val_accuracy: 0.8235\n","Epoch 8/10\n","7/7 [==============================] - 6s 815ms/step - loss: 0.1969 - accuracy: 0.9455 - val_loss: 0.6498 - val_accuracy: 0.8431\n","Epoch 9/10\n","7/7 [==============================] - 7s 1s/step - loss: 0.1754 - accuracy: 0.9307 - val_loss: 0.6314 - val_accuracy: 0.8235\n","Epoch 10/10\n","7/7 [==============================] - 6s 810ms/step - loss: 0.1149 - accuracy: 0.9653 - val_loss: 0.7522 - val_accuracy: 0.8235\n","2/2 [==============================] - 0s 112ms/step - loss: 0.7522 - accuracy: 0.8235\n","Test Loss: 0.7521930932998657\n","Test Accuracy: 0.8235294222831726\n","8/8 [==============================] - 2s 205ms/step\n","Images with Tumor: ['no 95.jpg', '20 no.jpg', '33 no.jpg', 'no 92.jpg', 'No20.jpg', '31 no.jpg', '44no.jpg', 'N20.JPG', 'Y113.JPG', 'Y102.jpg', 'Y166.JPG', 'Y103.jpg', 'Y114.JPG', 'Y16.JPG', 'Y170.JPG', 'Y165.JPG', 'Y117.JPG', 'Y17.jpg', 'Y154.jpg', 'Y2.jpg', 'Y181.jpg', 'Y167.JPG', 'Y111.JPG', 'Y188.jpg', 'Y160.JPG', 'Y156.JPG', 'Y168.jpg', 'Y20.jpg', 'Y157.JPG', 'Y159.JPG', 'Y10.jpg', 'Y194.jpg', 'Y164.JPG', 'Y185.jpg', 'Y180.jpg', 'Y19.JPG', 'Y21.jpg', 'Y192.JPG', 'Y104.jpg', 'Y183.jpg', 'Y106.jpg', 'Y107.jpg', 'Y1.jpg', 'Y108.jpg', 'Y146.JPG', 'Y147.JPG', 'Y15.jpg', 'Y112.JPG', 'Y184.JPG', 'Y169.jpg', 'Y153.jpg', 'Y109.JPG', 'Y186.jpg', 'Y101.jpg', 'Y12.jpg', 'Y22.jpg', 'Y23.JPG', 'Y163.JPG', 'Y13.jpg', 'Y182.JPG', 'Y193.JPG', 'Y100.JPG', 'Y158.JPG', 'Y116.JPG', 'Y105.jpg', 'Y115.JPG', 'Y148.JPG', 'Y195.JPG', 'Y155.JPG', 'Y18.JPG', 'Y161.JPG', 'Y11.jpg', 'Y14.jpg', 'Y120.JPG', 'Y162.jpg', 'Y187.jpg', 'Y24.jpg', 'Y35.jpg', 'Y53.jpg', 'Y74.jpg', 'Y25.jpg', 'Y52.jpg', 'Y257.jpg', 'Y44.JPG', 'Y32.jpg', 'Y39.jpg', 'Y79.jpg', 'Y76.jpg', 'Y252.jpg', 'Y81.jpg', 'Y92.jpg', 'Y85.JPG', 'Y66.JPG', 'Y250.jpg', 'Y69.jpg', 'Y4.jpg', 'Y259.JPG', 'Y27.jpg', 'Y254.jpg', 'Y243.JPG', 'Y45.JPG', 'Y82.jpg', 'Y42.jpg', 'Y255.JPG', 'Y78.jpg', 'Y256.JPG', 'Y26.jpg', 'Y49.JPG', 'Y31.jpg', 'Y30.jpg', 'Y247.JPG', 'Y55.jpg', 'Y59.JPG', 'Y97.JPG', 'Y37.jpg', 'Y56.jpg', 'Y92.png', 'Y62.jpg', 'Y61.jpg', 'Y71.JPG', 'Y40.JPG', 'Y77.jpg', 'Y65.JPG', 'Y47.JPG', 'Y58.JPG', 'Y75.JPG', 'Y249.JPG', 'Y258.JPG', 'Y248.JPG', 'Y54.jpg', 'Y70.jpg', 'Y46.jpg', 'Y95.jpg', 'Y51.jpg', 'Y60.jpg', 'Y73.jpg', 'Y242.JPG', 'Y7.jpg', 'Y29.jpg', 'Y251.JPG', 'Y50.JPG', 'Y3.jpg', 'Y41.jpg', 'Y89.JPG', 'Y98.JPG', 'Y86.JPG', 'Y33.jpg', 'Y38.jpg', 'Y244.JPG', 'Y96.jpg', 'Y36.JPG', 'Y9.jpg', 'Y6.jpg', 'Y99.JPG', 'Y246.JPG', 'Y90.jpg', 'Y8.jpg', 'Y91.jpg', 'Y34.jpg', 'Y253.JPG']\n","Images without Tumor: ['36 no.jpg', 'no.jpg', '21 no.jpg', 'no 97.jpg', '41 no.jpg', 'no 89.jpg', 'No21.jpg', 'no 96.jpg', '9 no.jpg', 'No18.jpg', 'no 94.jpg', '25 no.jpg', 'no 3.jpg', 'no 7.jpeg', '5 no.jpg', 'N26.JPG', '6 no.jpg', 'No15.jpg', 'no 10.jpg', '28 no.jpg', '13 no.jpg', 'no 2.jpg', '30 no.jpg', 'N2.JPG', 'N21.jpg', '27 no.jpg', 'no 6.jpg', 'No13.jpg', '47 no.jpg', '15 no.jpg', 'N19.JPG', 'no 5.jpeg', '12 no.jpg', '38 no.jpg', '17 no.jpg', 'N22.JPG', '8 no.jpg', '3 no.jpg', '46 no.jpg', '22 no.jpg', '37 no.jpg', '32 no.jpg', '42 no.jpg', '2 no.jpeg', 'No22.jpg', 'no 100.jpg', '50 no.jpg', '39 no.jpg', 'no 1.jpg', 'no 99.jpg', 'N1.JPG', 'No17.jpg', 'N11.jpg', '49 no.jpg', 'No16.jpg', '29 no.jpg', '34 no.jpg', '26 no.jpg', '23 no.jpg', '14 no.jpg', 'N3.jpg', 'N17.jpg', 'N16.jpg', '24 no.jpg', 'No19.jpg', '4 no.jpg', '10 no.jpg', 'No14.jpg', '45 no.jpg', 'no 923.jpg', '11 no.jpg', 'N5.jpg', '43 no.jpg', 'No11.jpg', '1 no.jpeg', 'no 8.jpg', 'No12.jpg', '40 no.jpg', '48 no.jpeg', '18 no.jpg', 'no 91.jpeg', '7 no.jpg', 'N15.jpg', 'no 9.png', '19 no.jpg', 'N6.jpg', '35 no.jpg', 'no 98.jpg', 'no 4.jpg', 'no 90.jpg', 'Y67.JPG', 'Y245.jpg', 'Y28.jpg']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"80L1DFQ3ZGeF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CvR2lgEFZGby"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8X5c6rEFZGXg"},"execution_count":null,"outputs":[]}]}